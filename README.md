# CDAsmoother: Physics-Informed Neural Networks for Fluid Dynamics

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.9+-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A comprehensive implementation of **CDAnet** (Continuous Data Assimilation Network), a physics-informed deep neural network for high-resolution reconstruction of Rayleigh-BÃ©nard convection from sparse observations.

## Features

- **CDAnet Architecture**: Complete implementation with 3D U-Net + Physics-Informed MLP
- **High-Resolution Reconstruction**: Downscale from low-resolution observations to high-resolution fields
- **Physics Integration**: PDE residuals as soft constraints in loss function
- **Optimized RB Data Generator**: 4x faster simulation with flexible visualization options
- **Comprehensive Evaluation**: RRMSE metrics, temporal evolution analysis, and generalization testing
- **Production Ready**: Modular codebase with configuration management and experiment tracking
- **Monitoring**: TensorBoard/WandB integration with detailed logging
- **Space-Efficient Visualization**: Smart controls for balancing quality and storage

## Architecture

CDAnet combines two key components:

1. **3D U-Net Feature Extractor**
   - Modified U-Net with Inception-ResNet blocks
   - Processes spatio-temporal clips with skip connections
   - Multi-scale feature extraction

2. **Physics-Informed MLP**
   - Coordinate-based neural network
   - Automatic differentiation for PDE residuals
   - Enforces Rayleigh-BÃ©nard governing equations

### Model Pipeline
```
Low-res clip [B, 4, T, H, W] â†’ 3D U-Net â†’ Features [B, C, T, H, W]
                                              â†“
Coordinates [B, N, 3] + Features â†’ MLP â†’ High-res fields [B, N, 4]
```

## Project Structure

```
CDAsmoother/
â”œâ”€â”€ cdanet/                          # Main CDAnet package
â”‚   â”œâ”€â”€ models/                      # Neural network architectures
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ cdanet.py               # Complete CDAnet model
â”‚   â”‚   â”œâ”€â”€ unet3d.py               # 3D U-Net feature extractor
â”‚   â”‚   â”œâ”€â”€ mlp.py                  # Physics-informed MLP
â”‚   â”‚   â””â”€â”€ inception_resnet.py     # Inception-ResNet blocks
â”‚   â”œâ”€â”€ data/                        # Data loading and preprocessing
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ dataset.py              # RB dataset classes
â”‚   â”‚   â””â”€â”€ data_loader.py          # Data module with preprocessing
â”‚   â”œâ”€â”€ training/                    # Training utilities
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ trainer.py              # Main training loop
â”‚   â”‚   â””â”€â”€ losses.py               # Combined regression + PDE loss
â”‚   â”œâ”€â”€ evaluation/                  # Model evaluation
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ evaluator.py            # Comprehensive evaluation metrics
â”‚   â”œâ”€â”€ utils/                       # Utility functions
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ logger.py               # Experiment logging
â”‚   â”‚   â”œâ”€â”€ metrics.py              # Evaluation metrics & visualization
â”‚   â”‚   â””â”€â”€ rb_visualization.py     # Rayleigh-BÃ©nard visualization tools
â”‚   â”œâ”€â”€ config/                      # Configuration management
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ config.py               # Experiment configurations
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ train_cdanet.py                  # Main training script
â”œâ”€â”€ minimal_train.py                 # Minimal training example (verification)
â”œâ”€â”€ working_training_example.py      # Working pipeline demonstration
â”œâ”€â”€ verify_pipeline.py               # Complete pipeline verification
â”œâ”€â”€ evaluate_cdanet.py               # Evaluation script
â”œâ”€â”€ visualize_results.py             # Result visualization script
â”œâ”€â”€ rb_simulation.py                 # Optimized RB data generator
â”œâ”€â”€ convert_rb_data.py               # Data format converter
â”œâ”€â”€ requirements.txt                 # Python dependencies
â””â”€â”€ README.md                        # This file
```

## Installation

### Prerequisites
- Python 3.8+
- CUDA-capable GPU (recommended)
- 8GB+ GPU memory

### Setup
```bash
# Clone the repository
git clone https://github.com/yourusername/CDAsmoother.git
cd CDAsmoother

# Install dependencies
pip install -r requirements.txt

# Or with conda
conda env create -f environment.yml
conda activate cdasmoother
```

### Dependencies
- **Core**: PyTorch, NumPy, SciPy, HDF5
- **Visualization**: Matplotlib, Seaborn
- **Logging**: TensorBoard, Weights & Biases (optional)
- **Data**: scikit-learn, pandas

## Pipeline Verification

Before running full training, you can verify that all components are working correctly:

### 1. Quick Pipeline Test
```bash
# Run complete pipeline verification
python3 verify_pipeline.py

# Run minimal training example (1 epoch, small batch)
python3 minimal_train.py

# Run working training example with real data
python3 working_training_example.py
```

The verification scripts will:
- âœ… Test data loading from RB simulation files
- âœ… Verify CDAnet model creation and forward pass
- âœ… Test training step with loss computation and backpropagation
- âœ… Verify checkpoint saving and loading
- âœ… Save verification results to `./outputs/`

### 2. Verify Training Pipeline
```bash
# This runs a complete but minimal training loop
python3 working_training_example.py
```

Expected output:
```
ðŸš€ CDAsmoother Working Training Example
âœ… Data loaded: X batches available
âœ… Model created: XXX,XXX parameters
âœ… Forward pass successful!
âœ… Backward pass successful!
âœ… Checkpoint saved: ./checkpoints/working_example_checkpoint.pth
ðŸŽ‰ SUCCESS! CDAsmoother Pipeline is Working!
```

## Quick Start

### 1. Generate Training Data

#### Option A: Using the Optimized RB Simulator (Recommended)
```bash
# Quick test with visualization
python3 rb_simulation.py --test --visualize

# Generate full dataset for training
python3 rb_simulation.py --Ra 1e5 1e6 1e7 --n_runs 25

# Fast mode for quick experiments
python3 rb_simulation.py --fast --visualize --viz_mode sparse

# Minimal visualization to save space
python3 rb_simulation.py --visualize --viz_mode minimal
```

#### Option B: Legacy Synthetic Data Generation
```bash
# Generate synthetic Rayleigh-BÃ©nard data (deprecated)
python -c "
from cdanet.data import RBDataModule
dm = RBDataModule('./rb_data_numerical')
dm.create_synthetic_data('./rb_data_numerical/rb_data_Ra_1e5.h5', Ra=1e5, nx=768, ny=256, nt=600)
"
```

### 2. Train CDAnet

#### Option A: Quick Training Test (Recommended for first run)
```bash
# Run minimal training to verify everything works (1 epoch)
python3 minimal_train.py

# Run working example with real data (quick verification)
python3 working_training_example.py
```

#### Option B: Full Training
```bash
# Basic training with default parameters
python3 train_cdanet.py --Ra 1e5 --spatial_downsample 4 --temporal_downsample 4

# Advanced training with custom parameters
python3 train_cdanet.py \
    --Ra 1e6 \
    --spatial_downsample 2 \
    --temporal_downsample 2 \
    --batch_size 16 \
    --num_epochs 200 \
    --learning_rate 0.05 \
    --lambda_pde 0.1 \
    --feature_channels 512 \
    --experiment_name "my_experiment"

# CPU-friendly training (smaller model)
python3 train_cdanet.py \
    --Ra 1e5 \
    --spatial_downsample 4 \
    --temporal_downsample 4 \
    --batch_size 2 \
    --feature_channels 128 \
    --mlp_width 256 \
    --device cpu
```

### 3. Evaluate Model
```bash
# Standard evaluation
python3 evaluate_cdanet.py \
    --checkpoint checkpoints/best_model.pth \
    --output_dir evaluation_results

# Generalization testing
python3 evaluate_cdanet.py \
    --checkpoint checkpoints/best_model.pth \
    --generalization \
    --test_ra 7e5 8e5 9e5 1.1e6 1.2e6 \
    --temporal_evolution \
    --physics_analysis
```

### 4. Visualize Results
```bash
# Create publication-quality visualizations from trained model
python3 visualize_results.py \
    --checkpoint checkpoints/best_model.pth \
    --data_dir ./rb_data_numerical \
    --variable T \
    --output_dir ./visualizations

# Create demo visualization with synthetic data
python3 visualize_results.py --demo --output_dir ./demo_viz

# Visualize different variables
python3 visualize_results.py --demo --variable u --output_dir ./velocity_viz
python3 visualize_results.py --demo --variable T --output_dir ./temperature_viz
```

## ðŸ”§ Configuration

### Predefined Configurations
The project includes predefined configurations matching the original paper:

```bash
# Use paper configurations
python3 train_cdanet.py --preset Ra_1e5_ds_4_4   # Ra=10^5, Î³_s=4, Î³_t=4
python3 train_cdanet.py --preset Ra_1e6_ds_2_2   # Ra=10^6, Î³_s=2, Î³_t=2
python3 train_cdanet.py --preset Ra_1e7_ds_2_2   # Ra=10^7, Î³_s=2, Î³_t=2
```

### Custom Configuration
Create a YAML configuration file:

```yaml
# config.yaml
model:
  feature_channels: 256
  mlp_hidden_dims: [512, 512, 512, 512]
  activation: 'softplus'

data:
  spatial_downsample: 4
  temporal_downsample: 4
  Ra_numbers: [1e5]
  batch_size: 32

training:
  num_epochs: 100
  learning_rate: 0.1
  use_amp: true

loss:
  lambda_pde: 0.01
  regression_norm: 'l1'
  pde_norm: 'l1'
```

Then run:
```bash
python3 train_cdanet.py --config config.yaml
```

## Results & Performance

### Expected Performance (from paper)
| Ra Number | Downsampling (Î³_s, Î³_t) | RRMSE (avg) |
|-----------|-------------------------|-------------|
| 10^5      | (2, 2)                  | <1%         |
| 10^5      | (4, 4)                  | ~1%         |
| 10^6      | (2, 2)                  | <1%         |
| 10^7      | (2, 2)                  | ~2%         |

### Key Features
- **Physics Integration**: PDE residuals enforce fluid dynamics laws
- **Multi-scale Learning**: Handles various downsampling factors
- **Temporal Consistency**: Maintains physical evolution over time
- **Generalization**: Transfers across different Rayleigh numbers

## ðŸ”¥ RB Data Generator Guide

### Overview
The optimized `rb_simulation.py` provides fast, realistic Rayleigh-BÃ©nard convection data generation with comprehensive visualization options. The generator has been optimized for:
- **4x faster simulation** (reduced grid size and samples)
- **10x faster I/O** (optimized HDF5 format)
- **70% smaller files** (improved compression)
- **Flexible visualization** (space-efficient options)

### Basic Usage

#### Quick Test
```bash
# Test the simulator (automatically uses fast mode)
python3 rb_simulation.py --test --visualize
```

#### Production Data Generation
```bash
# Standard dataset generation
python3 rb_simulation.py --Ra 1e5 1e6 1e7 --n_runs 25

# Fast mode for experiments (reduced resolution and samples)
python3 rb_simulation.py --fast --Ra 1e5 --n_runs 10

# Custom parameters with visualization
python3 rb_simulation.py \
    --Ra 1e5 \
    --n_runs 20 \
    --save_path ./my_rb_data \
    --visualize \
    --viz_mode sparse
```

### Visualization Options

The generator includes three visualization modes to balance quality and storage:

```bash
# Full visualization (every 25 samples, all runs)
python3 rb_simulation.py --test --visualize --viz_mode full

# Sparse visualization (every 50 samples, skip some runs) - default
python3 rb_simulation.py --test --visualize --viz_mode sparse

# Minimal visualization (every 100 samples, few runs)
python3 rb_simulation.py --test --visualize --viz_mode minimal

# With evolution animations (GIF format)
python3 rb_simulation.py --test --visualize --animation
```

### Performance Modes

| Mode | Grid Size | Samples/Run | Use Case |
|------|-----------|-------------|----------|
| **Test** (`--test`) | 384Ã—128 | 25 | Quick validation (auto-fast) |
| **Fast** (`--fast`) | 384Ã—128 | 25 | Quick experiments, debugging |
| **Standard** | 512Ã—170 | 100 | Development, small datasets |

### Visualization Modes

| Mode | Frequency | Run Skip | Max per Run | Storage Impact |
|------|-----------|----------|-------------|----------------|
| **Full** | Every 25 samples | None (all runs) | Unlimited | High storage |
| **Sparse** | Every 50 samples | 2/3 runs skipped | 5 images | Medium storage |
| **Minimal** | Every 100 samples | 4/5 runs skipped | 3 images | Low storage |

### Output Structure
```
rb_data_numerical/                 # Default output directory
â”œâ”€â”€ rb_data_Ra_1e+05_run_00.h5     # Individual run files (optimized format)
â”œâ”€â”€ rb_data_Ra_1e+05_run_01.h5
â”œâ”€â”€ ...
â”œâ”€â”€ rb_data_Ra_1e+05.h5             # Consolidated file (created by convert_rb_data.py)
â””â”€â”€ visualizations/
    â””â”€â”€ Ra_1e+05/
        â”œâ”€â”€ rb_viz_run00_sample000.png
        â”œâ”€â”€ rb_viz_run00_sample025.png
        â”œâ”€â”€ rb_evolution_run00.gif      # If --animation enabled
        â””â”€â”€ summary.html                # Interactive overview
```

### Data Format
Generated files use an optimized HDF5 format:
```python
# File structure
f['data']     # Shape: (n_samples, height, width, 4) - [T, p, u, v]
f['times']    # Shape: (n_samples,) - Time stamps
f.attrs      # Metadata: Ra, grid size, etc.
```

### Data Conversion
Convert individual runs to consolidated format for training:
```bash
# Convert all available data
python3 convert_rb_data.py

# Or use programmatically
python3 -c "
from convert_rb_data import convert_rb_data_to_cdanet_format
convert_rb_data_to_cdanet_format('./rb_data_numerical', Ra=1e5)
"
```

### Performance Tips
1. **Use test mode** (`--test`) for initial validation
2. **Choose appropriate viz mode**: `minimal` for large datasets, `full` for detailed analysis
3. **Use fast mode** (`--fast`) for experiments and debugging
4. **Skip animations** unless needed (they add significant storage)
5. **Monitor disk space** - full datasets can be several GB

### Example Workflows

#### Development Workflow
```bash
# 1. Quick test with visualization
python3 rb_simulation.py --test --visualize

# 2. Small development dataset
python3 rb_simulation.py --fast --Ra 1e5 --n_runs 5 --visualize --viz_mode sparse

# 3. Check results
open rb_data_numerical/visualizations/Ra_1e+05/summary.html
```

#### Production Workflow
```bash
# 1. Generate full training dataset (space-efficient visualization)
python3 rb_simulation.py \
    --Ra 1e5 1e6 1e7 \
    --n_runs 25 \
    --visualize \
    --viz_mode minimal

# 2. Convert to consolidated format
python3 convert_rb_data.py

# 3. Verify data quality
ls -lh rb_data_numerical/rb_data_Ra_*.h5
```

## ðŸ” Troubleshooting & Tips

### Before Training
1. **Always verify the pipeline first**:
   ```bash
   python3 verify_pipeline.py
   ```

2. **Start with minimal training**:
   ```bash
   python3 working_training_example.py
   ```

3. **Check data availability**:
   ```bash
   ls -la ./rb_data_numerical/
   # Should contain rb_data_Ra_*.h5 files
   ```

### Training Issues

#### Memory Issues (CPU Training)
```bash
# Use smaller model and batch size
python3 train_cdanet.py \
    --Ra 1e5 \
    --batch_size 1 \
    --feature_channels 64 \
    --mlp_width 128 \
    --device cpu \
    --num_workers 0
```

#### GPU Issues
```bash
# Auto-detect device (cuda/mps/cpu)
python3 train_cdanet.py --device auto

# Force CPU if GPU has issues
python3 train_cdanet.py --device cpu
```

#### Data Loading Issues
```bash
# Generate data if missing
python3 train_cdanet.py --generate_data --Ra 1e5

# Or manually generate RB data
python3 rb_simulation.py --test --visualize
```

### Performance Optimization
- **CPU Training**: Use `--feature_channels 64-128` and `--batch_size 1-2`
- **GPU Training**: Use `--feature_channels 256-512` and `--batch_size 8-32`
- **Quick Testing**: Use `minimal_train.py` or `working_training_example.py`
- **Debugging**: Add `--debug` flag to training script

### Output Files
```
./checkpoints/           # Model checkpoints
./outputs/              # Training logs and results
./visualizations/       # Generated plots
./logs/                # TensorBoard logs
```

## Advanced Usage

### Custom Training Loop
```python
from cdanet import CDAnet, ExperimentConfig, RBDataModule, CDAnetTrainer
from cdanet.utils import Logger

# Setup configuration
config = ExperimentConfig()
config.data.Ra_numbers = [1e6]
config.training.num_epochs = 200

# Create model and data
model = CDAnet(**config.model.__dict__)
data_module = RBDataModule(**config.data.__dict__)
data_module.setup(config.data.Ra_numbers)

# Setup logger and trainer
logger = Logger(log_dir='./logs', experiment_name='custom_experiment')
trainer = CDAnetTrainer(config, model, data_module, logger)

# Train
trainer.train()
```


## Physics Implementation

### Governing Equations
The network enforces Rayleigh-BÃ©nard convection equations as soft constraints:

1. **Continuity**: âˆ‡ Â· **u** = 0
2. **Momentum**: âˆ‚**u**/âˆ‚t + (**u** Â· âˆ‡)**u** = -âˆ‡p + Prâˆ‡Â²**u** + RaPrT**Äµ**
3. **Energy**: âˆ‚T/âˆ‚t + **u** Â· âˆ‡T = âˆ‡Â²T

### Loss Function
```
L_total = ||y_pred - y_true||â‚ + Î» Ã— ||PDE_residual||â‚
```

Where PDE residual includes all governing equations computed via automatic differentiation.



## Citation


## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

**â­ Star this repository if you find it useful!**
