#!/usr/bin/env python3
"""
Simple but stable Rayleigh-BÃ©nard data generator
Uses analytical patterns with physics-informed time evolution
Avoids numerical instabilities while providing realistic training data
"""

import numpy as np
import h5py
import os
import matplotlib.pyplot as plt
import argparse


def generate_stable_rb_data(Ra=1e5, nx=256, ny=256, t=0.0, dt=0.1, run_id=0):
    """
    Generate realistic RB convection patterns with diverse turbulent structures
    Based on physical understanding with reduced regularity
    """
    Lx, Ly = 3.0, 1.0
    x = np.linspace(0, Lx, nx)
    y = np.linspace(0, Ly, ny)
    X, Y = np.meshgrid(x, y)

    # Add run-specific randomness to break periodicity
    np.random.seed(int(run_id * 1000 + t * 100) % 2147483647)

    # Base temperature field (linear + perturbations)
    T = 1.0 - Y / Ly

    # Generate more realistic convection with multiple scales and randomness
    # Large-scale convection cells (less regular)
    n_large_cells = np.random.randint(2, 5)  # 2-4 large cells
    for i in range(n_large_cells):
        phase_x = np.random.uniform(0, 2*np.pi)
        phase_y = np.random.uniform(0, np.pi)
        freq_x = np.random.uniform(1.5, 3.5)  # Variable frequency
        amp = np.random.uniform(0.03, 0.08)   # Variable amplitude
        omega = np.random.uniform(0.3, 0.8)   # Variable time evolution

        T += amp * np.sin(freq_x * np.pi * X / Lx + phase_x + omega * t) * \
             np.sin(np.pi * Y / Ly + phase_y)

    # Medium-scale turbulent structures
    n_medium_cells = np.random.randint(3, 7)  # 3-6 medium cells
    for i in range(n_medium_cells):
        phase_x = np.random.uniform(0, 2*np.pi)
        phase_y = np.random.uniform(0, 2*np.pi)
        freq_x = np.random.uniform(4, 8)      # Higher frequency
        freq_y = np.random.uniform(1.5, 3)    # Variable y frequency
        amp = np.random.uniform(0.015, 0.035) # Smaller amplitude
        omega = np.random.uniform(0.8, 1.8)   # Faster evolution

        T += amp * np.sin(freq_x * np.pi * X / Lx + phase_x + omega * t) * \
             np.sin(freq_y * np.pi * Y / Ly + phase_y)

    # Small-scale fluctuations (breaking up regular patterns)
    n_small_cells = np.random.randint(5, 12)  # Many small fluctuations
    for i in range(n_small_cells):
        phase_x = np.random.uniform(0, 2*np.pi)
        phase_y = np.random.uniform(0, 2*np.pi)
        freq_x = np.random.uniform(8, 16)     # High frequency
        freq_y = np.random.uniform(3, 6)      # Higher y frequency
        amp = np.random.uniform(0.005, 0.02)  # Small amplitude
        omega = np.random.uniform(1.5, 3.0)   # Fast evolution

        T += amp * np.sin(freq_x * np.pi * X / Lx + phase_x + omega * t) * \
             np.cos(freq_y * np.pi * Y / Ly + phase_y)  # Mix sin/cos

    # Add localized temperature anomalies (realistic thermal plumes)
    n_plumes = np.random.randint(2, 6)
    for i in range(n_plumes):
        # Random plume locations
        x_center = np.random.uniform(0.2, 0.8) * Lx
        y_center = np.random.uniform(0.2, 0.8) * Ly
        width_x = np.random.uniform(0.3, 0.8)
        width_y = np.random.uniform(0.15, 0.4)
        amplitude = np.random.uniform(0.02, 0.06)

        # Gaussian-like thermal plume
        plume = amplitude * np.exp(-((X - x_center)**2 / width_x**2 +
                                   (Y - y_center)**2 / width_y**2))
        # Time modulation
        time_mod = np.sin(np.random.uniform(0.5, 2.0) * t + np.random.uniform(0, 2*np.pi))
        T += plume * time_mod

    # Apply boundary conditions
    T[0, :] = 1.0   # Hot bottom
    T[-1, :] = 0.0  # Cold top

    # Generate diverse velocity fields from stream function
    psi = np.zeros_like(X)

    # Multiple circulation patterns with randomness
    n_circulations = np.random.randint(2, 5)
    for i in range(n_circulations):
        phase_x = np.random.uniform(0, 2*np.pi)
        phase_y = np.random.uniform(0, np.pi)
        freq_x = np.random.uniform(1, 4)      # Variable circulation size
        freq_y = np.random.uniform(0.5, 2)    # Variable vertical structure
        amp = np.random.uniform(0.1, 0.4)     # Variable strength
        omega = np.random.uniform(0.2, 1.0)   # Variable time evolution

        psi += amp * np.sin(freq_x * np.pi * X / Lx + phase_x + omega * t) * \
               np.sin(freq_y * np.pi * Y / Ly + phase_y)

    # u = -âˆ‚Ïˆ/âˆ‚y, v = âˆ‚Ïˆ/âˆ‚x
    u = np.zeros_like(X)
    v = np.zeros_like(X)

    # Compute derivatives numerically
    dy = y[1] - y[0]
    dx = x[1] - x[0]

    # u = -âˆ‚Ïˆ/âˆ‚y
    u[1:-1, :] = -(psi[2:, :] - psi[:-2, :]) / (2 * dy)
    # v = âˆ‚Ïˆ/âˆ‚x
    v[:, 1:-1] = (psi[:, 2:] - psi[:, :-2]) / (2 * dx)

    # Apply no-slip boundary conditions
    u[0, :] = u[-1, :] = 0.0
    v[0, :] = v[-1, :] = 0.0

    # Periodic in x
    u[:, 0] = u[:, -1]
    v[:, 0] = v[:, -1]

    # Generate pressure field from continuity and momentum
    p = np.zeros_like(X)
    # Hydrostatic pressure
    p = -0.1 * Y + 0.5

    # Add dynamic pressure from velocity gradients
    # âˆ‡Â²p = -Ï(âˆ‚u/âˆ‚x âˆ‚v/âˆ‚y - âˆ‚u/âˆ‚y âˆ‚v/âˆ‚x)
    dudx = np.gradient(u, axis=1) / dx
    dvdy = np.gradient(v, axis=0) / dy
    dudy = np.gradient(u, axis=0) / dy
    dvdx = np.gradient(v, axis=1) / dx

    p += -0.2 * (dudx * dvdy - dudy * dvdx)

    # Add small time-dependent pressure fluctuations
    omega_p = np.random.uniform(0.5, 1.5)  # Random pressure oscillation
    p += 0.1 * np.sin(2 * np.pi * X / Lx + omega_p * t * 1.5) * np.cos(np.pi * Y / Ly)

    return T, u, v, p


def generate_training_dataset(Ra=1e5, n_runs=5, n_samples=50, nx=128, ny=64, save_path='rb_data_numerical'):
    """Generate training dataset with stable time evolution"""
    os.makedirs(save_path, exist_ok=True)

    print(f"ğŸŒ¡ï¸ Stable RB Data Generation")
    print(f"  Rayleigh number: Ra = {Ra:.0e}")
    print(f"  Runs: {n_runs}")
    print(f"  Samples per run: {n_samples}")
    print(f"  Grid: {nx}Ã—{ny}")
    print()

    all_data = []

    for run in range(n_runs):
        print(f"  ğŸƒ Run {run+1}/{n_runs}")

        run_data = []
        dt = 0.1  # Time step between samples
        t_offset = run * 10.0  # Different initial time for each run

        for sample in range(n_samples):
            t = t_offset + sample * dt

            # Generate snapshot with run-specific diversity
            T, u, v, p = generate_stable_rb_data(Ra=Ra, nx=nx, ny=ny, t=t, dt=dt, run_id=run)

            # Save data
            frame_data = {
                'temperature': T.copy(),
                'velocity_x': u.copy(),
                'velocity_y': v.copy(),
                'pressure': p.copy(),
                'time': t
            }
            run_data.append(frame_data)

            if sample % 10 == 0:
                print(f"      Sample {sample+1}/{n_samples}")

        # Save individual run
        filename = f'{save_path}/rb_data_Ra_{Ra:.0e}_run_{run:02d}.h5'
        with h5py.File(filename, 'w') as f:
            # Add run-level attributes for training compatibility
            f.attrs['Ra'] = Ra
            f.attrs['Pr'] = 0.7
            f.attrs['nx'] = nx
            f.attrs['ny'] = ny
            f.attrs['n_samples'] = n_samples
            f.attrs['run_id'] = run

            for i, frame in enumerate(run_data):
                grp = f.create_group(f'frame_{i:03d}')
                for key, value in frame.items():
                    if key != 'time':
                        grp.create_dataset(key, data=value)
                    else:
                        grp.attrs['time'] = value

        print(f"    âœ… Saved: {filename}")
        all_data.append(run_data)

    # Create consolidated dataset
    create_consolidated_dataset(save_path, Ra, all_data, nx, ny)

    return all_data


def create_consolidated_dataset(save_path, Ra, all_data, nx, ny):
    """Create consolidated dataset compatible with training"""
    n_runs = len(all_data)
    n_samples = len(all_data[0])

    print(f"\nğŸ“¦ Creating consolidated dataset: {n_runs} runs Ã— {n_samples} samples")

    # Initialize arrays
    p_data = np.zeros((n_runs, n_samples, ny, nx), dtype=np.float32)
    b_data = np.zeros((n_runs, n_samples, ny, nx), dtype=np.float32)  # Temperature -> b
    u_data = np.zeros((n_runs, n_samples, ny, nx), dtype=np.float32)
    w_data = np.zeros((n_runs, n_samples, ny, nx), dtype=np.float32)  # v -> w

    # Fill arrays
    for run_idx, run_data in enumerate(all_data):
        for sample_idx, frame in enumerate(run_data):
            p_data[run_idx, sample_idx] = frame['pressure']
            b_data[run_idx, sample_idx] = frame['temperature']
            u_data[run_idx, sample_idx] = frame['velocity_x']
            w_data[run_idx, sample_idx] = frame['velocity_y']

    # Save consolidated dataset
    output_file = f'{save_path}/rb2d_ra{Ra:.0e}_consolidated.h5'
    with h5py.File(output_file, 'w') as f:
        f.create_dataset('p', data=p_data, compression='gzip')
        f.create_dataset('b', data=b_data, compression='gzip')
        f.create_dataset('u', data=u_data, compression='gzip')
        f.create_dataset('w', data=w_data, compression='gzip')

        # Add metadata compatible with training script
        f.attrs['Ra'] = Ra
        f.attrs['Pr'] = 0.7
        f.attrs['nx'] = nx
        f.attrs['ny'] = ny
        f.attrs['Lx'] = 3.0
        f.attrs['Ly'] = 1.0
        f.attrs['n_runs'] = n_runs
        f.attrs['n_samples'] = n_samples
        f.attrs['simulation_type'] = 'stable_analytical'
        f.attrs['format'] = 'consolidated_training_compatible'

    print(f"âœ… Consolidated dataset: {output_file}")

    # Print statistics
    print(f"\nğŸ“Š Data statistics:")
    print(f"  Temperature range: [{np.min(b_data):.3f}, {np.max(b_data):.3f}]")
    print(f"  Pressure range: [{np.min(p_data):.3f}, {np.max(p_data):.3f}]")
    print(f"  U-velocity range: [{np.min(u_data):.3f}, {np.max(u_data):.3f}]")
    print(f"  V-velocity range: [{np.min(w_data):.3f}, {np.max(w_data):.3f}]")

    # Check temporal evolution
    temp_change = np.max(np.abs(b_data[0, 0] - b_data[0, -1]))
    vel_change = np.max(np.abs(u_data[0, 0] - u_data[0, -1]))
    print(f"  âœ… Temporal evolution - Temperature: {temp_change:.4f}, Velocity: {vel_change:.4f}")

    return output_file


def visualize_data(output_file):
    """Create visualization of the data"""
    print(f"\nğŸ¨ Creating visualization: {output_file}")

    with h5py.File(output_file, 'r') as f:
        b_data = f['b'][:]
        p_data = f['p'][:]
        u_data = f['u'][:]
        w_data = f['w'][:]

        n_runs, n_samples, ny, nx = b_data.shape
        print(f"  Data shape: {n_runs} runs Ã— {n_samples} samples Ã— {ny}Ã—{nx}")

    # Select time steps for visualization
    run_idx = 0
    time_steps = [0, n_samples//4, n_samples//2, 3*n_samples//4, n_samples-1]

    # Create visualization
    fig, axes = plt.subplots(4, len(time_steps), figsize=(15, 12))
    fig.suptitle('Stable Rayleigh-BÃ©nard Simulation (Time Evolution)', fontsize=16)

    for i, t in enumerate(time_steps):
        # Temperature
        im1 = axes[0, i].imshow(b_data[run_idx, t], cmap='RdBu_r', aspect='equal')
        axes[0, i].set_title(f'Temperature t={t}')
        axes[0, i].set_xticks([])
        axes[0, i].set_yticks([])

        # Pressure
        im2 = axes[1, i].imshow(p_data[run_idx, t], cmap='viridis', aspect='equal')
        axes[1, i].set_title(f'Pressure t={t}')
        axes[1, i].set_xticks([])
        axes[1, i].set_yticks([])

        # U velocity
        im3 = axes[2, i].imshow(u_data[run_idx, t], cmap='RdBu', aspect='equal')
        axes[2, i].set_title(f'U Velocity t={t}')
        axes[2, i].set_xticks([])
        axes[2, i].set_yticks([])

        # V velocity
        im4 = axes[3, i].imshow(w_data[run_idx, t], cmap='RdBu', aspect='equal')
        axes[3, i].set_title(f'V Velocity t={t}')
        axes[3, i].set_xticks([])
        axes[3, i].set_yticks([])

    # Add colorbars
    plt.colorbar(im1, ax=axes[0, :], shrink=0.6, label='Temperature')
    plt.colorbar(im2, ax=axes[1, :], shrink=0.6, label='Pressure')
    plt.colorbar(im3, ax=axes[2, :], shrink=0.6, label='U Velocity')
    plt.colorbar(im4, ax=axes[3, :], shrink=0.6, label='V Velocity')

    plt.tight_layout()

    viz_file = f"{os.path.dirname(output_file)}/stable_rb_visualization.png"
    plt.savefig(viz_file, dpi=150, bbox_inches='tight')
    print(f"âœ… Visualization saved: {viz_file}")
    plt.close()

    return viz_file


def main():
    parser = argparse.ArgumentParser(description='Generate stable Rayleigh-BÃ©nard data')
    parser.add_argument('--Ra', type=float, default=1e5, help='Rayleigh number')
    parser.add_argument('--n_runs', type=int, default=10, help='Number of runs')
    parser.add_argument('--n_samples', type=int, default=100, help='Samples per run')
    parser.add_argument('--nx', type=int, default=256, help='Grid points in x')
    parser.add_argument('--ny', type=int, default=256, help='Grid points in y')
    parser.add_argument('--save_path', type=str, default='rb_data_numerical', help='Save directory')
    parser.add_argument('--visualize', action='store_true', help='Create visualizations')

    args = parser.parse_args()

    # Clear old data
    if os.path.exists(args.save_path):
        print(f"ğŸ—‘ï¸  Clearing old data in {args.save_path}")
        import shutil
        shutil.rmtree(args.save_path)

    # Generate stable data
    print("ğŸš€ Starting STABLE Rayleigh-BÃ©nard data generation...")
    print("Uses analytical patterns with proper time evolution - fast and stable!")

    all_data = generate_training_dataset(
        Ra=args.Ra,
        n_runs=args.n_runs,
        n_samples=args.n_samples,
        nx=args.nx,
        ny=args.ny,
        save_path=args.save_path
    )

    print(f"\nâœ… Stable data generation complete!")
    print(f"ğŸ“ Data saved in: {args.save_path}/")
    print(f"ğŸš€ Ready for CDAnet training with realistic, stable data!")

    # Create visualizations if requested
    if args.visualize:
        output_file = f'{args.save_path}/rb2d_ra{args.Ra:.0e}_consolidated.h5'
        visualize_data(output_file)


if __name__ == "__main__":
    main()