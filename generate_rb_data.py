#!/usr/bin/env python3
"""
åŸºäºä½ åŸæœ‰rb_simulation.pyçš„æ”¹è¿›ç‰ˆæœ¬
ä¿æŒä½ çš„ä»£ç ç»“æ„ï¼Œä½†ä¿®å¤æ•°å€¼ç¨³å®šæ€§å’Œç‰©ç†æ­£ç¡®æ€§
"""

import numpy as np
import h5py
import os
import matplotlib.pyplot as plt
import argparse
from scipy.ndimage import gaussian_filter


def generate_rb_snapshot_improved(nx, ny, Ra, time_step, dt=1e-3):
    """
    åŸºäºä½ åŸæœ‰generate_rb_snapshotå‡½æ•°çš„æ”¹è¿›ç‰ˆæœ¬
    ä¿æŒå¤šå°ºåº¦å¯¹æµç»“æ„ï¼Œä½†æé«˜æ•°å€¼ç¨³å®šæ€§
    """
    # åæ ‡ç½‘æ ¼ - ä¸ä½ çš„ä»£ç ä¸€è‡´
    Lx, Ly = 3.0, 1.0
    x = np.linspace(0, Lx, nx)
    y = np.linspace(0, Ly, ny)
    X, Y = np.meshgrid(x, y)

    # åŸºç¡€æ¸©åº¦åˆ†å¸ƒ - ä¸ä½ çš„ä»£ç ä¸€è‡´
    T_base = 1.0 - Y / Ly

    # æ·»åŠ 2DåŸºç¡€ç»“æ„ - ä¸ä½ çš„ä»£ç ä¸€è‡´ä½†å‡å°å¹…åº¦
    T_2d_variation = 0.05 * np.sin(2 * np.pi * X / Lx) * np.sin(np.pi * Y / Ly)
    T_2d_variation += 0.025 * np.sin(4 * np.pi * X / Lx) * np.sin(2 * np.pi * Y / Ly)

    T = T_base + T_2d_variation

    # æ—¶é—´å‚æ•°
    time = time_step * dt

    # å¯¹æµç»“æ„å‚æ•° - ä¸ä½ çš„ä»£ç ä¸€è‡´ä½†è°ƒæ•´æŒ¯å¹…
    n_large = 2
    amp_large = 0.2  # å‡å°ä»¥æé«˜ç¨³å®šæ€§

    n_medium = 4
    amp_medium = 0.1  # å‡å°ä»¥æé«˜ç¨³å®šæ€§

    n_small = 6  # å‡å°‘å°å°ºåº¦æ•°é‡
    amp_small = 0.03

    # åˆå§‹åŒ–åœº
    u = np.zeros_like(X)
    v = np.zeros_like(X)
    T_pert = np.zeros_like(X)

    # å¤§å°ºåº¦å¯¹æµå·ç­’ - ä¸ä½ çš„ä»£ç ç»“æ„ç›¸åŒ
    for i in range(n_large):
        x_center = (i + 0.5) * Lx / n_large
        kx_large = 2 * np.pi * n_large / Lx

        for j in range(2):
            ky_large = np.pi * (j + 1) / Ly

            # ç›¸ä½æ¼”åŒ– - ä¸ä½ çš„ä»£ç ä¸€è‡´ä½†æ·»åŠ ç¨³å®šæ€§
            phase_large = time * 0.3 + i * np.pi / n_large + j * np.pi / 2
            phase_large += 0.05 * np.sin(time * 0.2 + i + j)  # å‡å°éšæœºæ‰°åŠ¨

            # æŒ¯å¹…è°ƒåˆ¶
            amp_y = amp_large * (1.0 - 0.2 * j)

            # æµå‡½æ•°æ–¹æ³• - ä¸ä½ çš„ä»£ç ç›¸åŒ
            # u = -âˆ‚Ïˆ/âˆ‚y, v = âˆ‚Ïˆ/âˆ‚x
            u += amp_y * kx_large * np.cos(kx_large * (X - x_center)) * np.sin(ky_large * Y) * np.cos(phase_large)
            v += -amp_y * ky_large * np.sin(kx_large * (X - x_center)) * np.cos(ky_large * Y) * np.cos(phase_large)

            # æ¸©åº¦æ‰°åŠ¨
            T_pert += amp_y * 0.3 * np.sin(kx_large * (X - x_center)) * np.sin(ky_large * Y) * np.cos(phase_large + np.pi/4)

    # ä¸­å°ºåº¦å¯¹æµ - ä¸ä½ çš„ä»£ç ç»“æ„ç›¸åŒ
    for i in range(n_medium):
        kx_med = 2 * np.pi * n_medium / Lx

        for j in range(2):
            ky_med = np.pi * (j + 2) / Ly
            phase_med = time * 0.5 + i * np.pi / n_medium + j * np.pi / 3
            phase_med += 0.1 * np.sin(time * 0.4 + i + j)

            amp_med_y = amp_medium * (1.0 - 0.15 * j)

            u += amp_med_y * np.cos(kx_med * X + phase_med) * np.sin(ky_med * Y)
            v += amp_med_y * np.sin(kx_med * X + phase_med) * np.cos(ky_med * Y) * 0.5
            T_pert += amp_med_y * 0.2 * np.sin(kx_med * X + phase_med) * np.sin(ky_med * Y)

    # å°å°ºåº¦æ¹æµ - ä¸ä½ çš„ä»£ç ç›¸åŒä½†æ›´ç¨³å®š
    np.random.seed(int(time * 1000) % 10000)  # å¯é‡å¤çš„éšæœºæ•°
    for i in range(n_small):
        kx_small = 2 * np.pi * (n_small + 0.5 * np.random.normal()) / Lx
        ky_small = 2 * np.pi * (1 + i//2 + 0.3 * np.random.normal()) / Ly
        phase_small = time * (1.0 + 0.3 * i) + 0.1 * np.random.normal()

        amp_small_effective = amp_small * (1.0 + 0.3 * np.random.normal())

        u += amp_small_effective * np.cos(kx_small * X + phase_small) * np.sin(ky_small * Y)
        v += amp_small_effective * np.sin(kx_small * X + phase_small) * np.cos(ky_small * Y)
        T_pert += amp_small_effective * 0.15 * np.sin(kx_small * X + phase_small) * np.sin(ky_small * Y)

    # æ·»åŠ æ¸©åº¦æ‰°åŠ¨
    T += T_pert

    # çƒ­ç¾½æµ - ä¸ä½ çš„ä»£ç ç›¸åŒä½†å‚æ•°è°ƒæ•´
    for plume in range(3):  # å‡å°‘ç¾½æµæ•°é‡
        y_center = (plume + 0.5) * Ly / 3
        y_width = 0.15

        plume_phase = time * 0.3 + plume * np.pi / 2
        plume_strength = 0.08 * np.cos(plume_phase)  # å‡å°å¼ºåº¦

        y_profile = np.exp(-((Y - y_center) / y_width)**2)
        x_modulation = 1.0 + 0.2 * np.sin(2 * np.pi * X / Lx + plume * np.pi / 3)

        T += plume_strength * y_profile * x_modulation

    # è¾¹ç•Œå±‚æ•ˆåº” - ä¸ä½ çš„ä»£ç ç›¸åŒ
    boundary_layer = 0.08
    y_boundary_bottom = np.exp(-Y / boundary_layer)
    y_boundary_top = np.exp(-(Ly - Y) / boundary_layer)

    boundary_variation = 1.0 + 0.15 * np.sin(4 * np.pi * X / Lx + time)
    T += 0.05 * y_boundary_bottom * boundary_variation - 0.05 * y_boundary_top * boundary_variation

    # åº”ç”¨è¾¹ç•Œæ¡ä»¶ - ä¸ä½ çš„ä»£ç ç›¸åŒ
    T[0, :] = 1.0 + 0.03 * np.sin(2 * np.pi * x / Lx + time)
    T[-1, :] = 0.0 + 0.015 * np.sin(2 * np.pi * x / Lx + time * 0.7)

    # é€Ÿåº¦æ— æ»‘ç§»è¾¹ç•Œæ¡ä»¶
    u[0, :] = u[-1, :] = 0.0
    v[0, :] = v[-1, :] = 0.0

    # å‘¨æœŸè¾¹ç•Œæ¡ä»¶
    T[:, 0] = T[:, -1]
    u[:, 0] = u[:, -1]
    v[:, 0] = v[:, -1]

    # å‹åŠ›åœº - ä¸ä½ çš„ä»£ç ç›¸åŒä½†ç®€åŒ–
    dudx = np.gradient(u, axis=1) / (Lx / nx)
    dvdy = np.gradient(v, axis=0) / (Ly / ny)
    dudy = np.gradient(u, axis=0) / (Ly / ny)
    dvdx = np.gradient(v, axis=1) / (Lx / nx)

    p = -0.3 * (dudx**2 + dvdy**2 + 2 * dudy * dvdx)
    p += 0.1 * (1 - Y)  # é™æ°´å‹åŠ›

    # æ·»åŠ å™ªå£° - ä¸ä½ çš„ä»£ç ç›¸åŒä½†å‡å°å¹…åº¦
    noise_level = 0.005  # å‡å°å™ªå£°
    T += noise_level * np.random.normal(0, 1, T.shape)
    u += noise_level * 0.3 * np.random.normal(0, 1, u.shape)
    v += noise_level * 0.3 * np.random.normal(0, 1, v.shape)
    p += noise_level * 0.1 * np.random.normal(0, 1, p.shape)

    # å¹³æ»‘å¤„ç†ä»¥æé«˜ç¨³å®šæ€§
    T = gaussian_filter(T, sigma=0.3)
    u = gaussian_filter(u, sigma=0.3)
    v = gaussian_filter(v, sigma=0.3)
    p = gaussian_filter(p, sigma=0.3)

    # é‡æ–°åº”ç”¨è¾¹ç•Œæ¡ä»¶
    T[0, :] = 1.0
    T[-1, :] = 0.0
    u[0, :] = u[-1, :] = 0.0
    v[0, :] = v[-1, :] = 0.0

    return T, u, v, p


def generate_training_dataset_improved(Ra=1e5, n_runs=5, n_samples=50, nx=128, ny=64,
                                     save_path='rb_data_improved'):
    """
    åŸºäºä½ åŸæœ‰generate_training_datasetçš„æ”¹è¿›ç‰ˆæœ¬
    """
    os.makedirs(save_path, exist_ok=True)

    # å‚æ•°è®¾ç½®
    dt = 1e-3
    delta_t = 0.1

    print(f"ğŸŒ¡ï¸ åŸºäºåŸæœ‰ä»£ç çš„æ”¹è¿›RBæ•°æ®ç”Ÿæˆ")
    print(f"  ç‘åˆ©æ•°: Ra = {Ra:.0e}")
    print(f"  è¿è¡Œæ¬¡æ•°: {n_runs}")
    print(f"  æ¯æ¬¡æ ·æœ¬: {n_samples}")
    print(f"  ç½‘æ ¼: {nx}Ã—{ny}")
    print()

    all_data = []

    for run in range(n_runs):
        print(f"  è¿è¡Œ {run+1}/{n_runs}")

        run_data = []
        for sample in range(n_samples):
            # æ—¶é—´æ¼”åŒ–
            time_step = sample + run * n_samples * 2  # ç¡®ä¿ä¸åŒè¿è¡Œæœ‰ä¸åŒæ—¶é—´

            # ç”Ÿæˆå¿«ç…§
            T, u, v, p = generate_rb_snapshot_improved(nx, ny, Ra, time_step, dt)

            # ä¿å­˜æ•°æ®
            frame_data = {
                'temperature': T.copy(),
                'velocity_x': u.copy(),
                'velocity_y': v.copy(),
                'pressure': p.copy(),
                'time': time_step * dt
            }
            run_data.append(frame_data)

            if sample % 10 == 0:
                print(f"    æ ·æœ¬ {sample+1}/{n_samples}")

        # ä¿å­˜å•æ¬¡è¿è¡Œ - ä¸ä½ çš„åŸæœ‰æ ¼å¼å…¼å®¹
        filename = f'{save_path}/rb_data_Ra_{Ra:.0e}_run_{run:02d}.h5'
        with h5py.File(filename, 'w') as f:
            for i, frame in enumerate(run_data):
                grp = f.create_group(f'frame_{i:03d}')
                for key, value in frame.items():
                    if key != 'time':
                        grp.create_dataset(key, data=value)
                    else:
                        grp.attrs['time'] = value

        print(f"    ä¿å­˜: {filename}")
        all_data.append(run_data)

    # åˆ›å»ºåˆå¹¶æ•°æ®é›†
    create_consolidated_dataset_improved(save_path, Ra, all_data, nx, ny)

    return all_data


def create_consolidated_dataset_improved(save_path, Ra, all_data, nx, ny):
    """åˆ›å»ºåˆå¹¶æ•°æ®é›†ï¼Œå…¼å®¹è®­ç»ƒæ ¼å¼"""
    n_runs = len(all_data)
    n_samples = len(all_data[0])

    print(f"\nğŸ“¦ åˆ›å»ºåˆå¹¶æ•°æ®é›†: {n_runs} è¿è¡Œ Ã— {n_samples} æ ·æœ¬")

    # ä½¿ç”¨ä½ çš„æ•°æ®è½¬æ¢é€»è¾‘
    p_data = np.zeros((n_runs, n_samples, ny, nx), dtype=np.float32)
    b_data = np.zeros((n_runs, n_samples, ny, nx), dtype=np.float32)
    u_data = np.zeros((n_runs, n_samples, ny, nx), dtype=np.float32)
    w_data = np.zeros((n_runs, n_samples, ny, nx), dtype=np.float32)

    for run_idx, run_data in enumerate(all_data):
        for sample_idx, frame in enumerate(run_data):
            p_data[run_idx, sample_idx] = frame['pressure']
            b_data[run_idx, sample_idx] = frame['temperature']  # T -> b
            u_data[run_idx, sample_idx] = frame['velocity_x']
            w_data[run_idx, sample_idx] = frame['velocity_y']   # v -> w

    # ä¿å­˜ä¸ºè®­ç»ƒæ ¼å¼
    output_file = f'{save_path}/rb2d_ra{Ra:.0e}_consolidated.h5'

    with h5py.File(output_file, 'w') as f:
        f.create_dataset('p', data=p_data, compression='gzip')
        f.create_dataset('b', data=b_data, compression='gzip')
        f.create_dataset('u', data=u_data, compression='gzip')
        f.create_dataset('w', data=w_data, compression='gzip')

        f.attrs['Ra'] = Ra
        f.attrs['Pr'] = 0.7
        f.attrs['nx'] = nx
        f.attrs['ny'] = ny
        f.attrs['Lx'] = 3.0
        f.attrs['Ly'] = 1.0
        f.attrs['n_runs'] = n_runs
        f.attrs['n_samples'] = n_samples
        f.attrs['format'] = 'reference_compatible'
        f.attrs['source'] = 'improved_original'

    print(f"âœ… åˆå¹¶æ•°æ®é›†: {output_file}")

    # æ•°æ®ç»Ÿè®¡
    print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"  æ¸©åº¦èŒƒå›´: [{b_data.min():.3f}, {b_data.max():.3f}]")
    print(f"  å‹åŠ›èŒƒå›´: [{p_data.min():.3f}, {p_data.max():.3f}]")
    print(f"  Ué€Ÿåº¦èŒƒå›´: [{u_data.min():.3f}, {u_data.max():.3f}]")
    print(f"  Vé€Ÿåº¦èŒƒå›´: [{w_data.min():.3f}, {w_data.max():.3f}]")

    return output_file


def create_visualization(data_file, save_path):
    """åˆ›å»ºRBæ•°æ®å¯è§†åŒ–"""
    print(f"\nğŸ¨ åˆ›å»ºå¯è§†åŒ–: {data_file}")

    import h5py
    import matplotlib.pyplot as plt

    with h5py.File(data_file, 'r') as f:
        # è¯»å–æ•°æ®
        p_data = f['p'][:]  # å‹åŠ›
        b_data = f['b'][:]  # æ¸©åº¦(æµ®åŠ›)
        u_data = f['u'][:]  # Xé€Ÿåº¦
        w_data = f['w'][:]  # Yé€Ÿåº¦

        n_runs, n_samples, ny, nx = p_data.shape
        print(f"  æ•°æ®å½¢çŠ¶: {n_runs} runs Ã— {n_samples} samples Ã— {ny}Ã—{nx}")

    # é€‰æ‹©ç¬¬ä¸€ä¸ªè¿è¡Œçš„å‡ ä¸ªæ—¶é—´æ­¥è¿›è¡Œå¯è§†åŒ–
    run_idx = 0
    time_steps = [0, n_samples//4, n_samples//2, 3*n_samples//4, n_samples-1]

    # åˆ›å»ºå¯è§†åŒ–
    fig, axes = plt.subplots(4, len(time_steps), figsize=(15, 12))
    fig.suptitle(f'Rayleigh-Benard Convection Visualization (Run {run_idx+1})', fontsize=16)

    for i, t in enumerate(time_steps):
        # æ¸©åº¦åœº
        im1 = axes[0, i].imshow(b_data[run_idx, t], cmap='RdBu_r', aspect='equal')
        axes[0, i].set_title(f'Temperature t={t}')
        axes[0, i].set_xticks([])
        axes[0, i].set_yticks([])

        # å‹åŠ›åœº
        im2 = axes[1, i].imshow(p_data[run_idx, t], cmap='viridis', aspect='equal')
        axes[1, i].set_title(f'Pressure t={t}')
        axes[1, i].set_xticks([])
        axes[1, i].set_yticks([])

        # Xé€Ÿåº¦åœº
        im3 = axes[2, i].imshow(u_data[run_idx, t], cmap='RdBu', aspect='equal')
        axes[2, i].set_title(f'U Velocity t={t}')
        axes[2, i].set_xticks([])
        axes[2, i].set_yticks([])

        # Yé€Ÿåº¦åœº
        im4 = axes[3, i].imshow(w_data[run_idx, t], cmap='RdBu', aspect='equal')
        axes[3, i].set_title(f'W Velocity t={t}')
        axes[3, i].set_xticks([])
        axes[3, i].set_yticks([])

    # æ·»åŠ é¢œè‰²æ¡
    plt.colorbar(im1, ax=axes[0, :], shrink=0.6, label='Temperature')
    plt.colorbar(im2, ax=axes[1, :], shrink=0.6, label='Pressure')
    plt.colorbar(im3, ax=axes[2, :], shrink=0.6, label='U Velocity')
    plt.colorbar(im4, ax=axes[3, :], shrink=0.6, label='W Velocity')

    plt.tight_layout()

    # ä¿å­˜å›¾åƒ
    viz_file = f"{save_path}/rb_visualization.png"
    plt.savefig(viz_file, dpi=150, bbox_inches='tight')
    print(f"âœ… å¯è§†åŒ–ä¿å­˜: {viz_file}")

    # åˆ›å»ºå•ä¸ªæ ·æœ¬çš„æµåœºå¯è§†åŒ–
    fig2, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

    # é€‰æ‹©ä¸­é—´æ—¶é—´æ­¥
    mid_t = n_samples // 2
    T = b_data[run_idx, mid_t]
    U = u_data[run_idx, mid_t]
    W = w_data[run_idx, mid_t]

    # æ¸©åº¦åœºä½œä¸ºèƒŒæ™¯
    im = ax1.imshow(T, cmap='RdBu_r', aspect='equal', extent=[0, 3, 0, 1])
    ax1.set_title('Temperature Field')
    ax1.set_xlabel('x')
    ax1.set_ylabel('y')
    plt.colorbar(im, ax=ax1, label='Temperature')

    # æµåœºçŸ¢é‡å›¾
    x = np.linspace(0, 3, nx)
    y = np.linspace(0, 1, ny)
    X, Y = np.meshgrid(x, y)

    # é™é‡‡æ ·ä»¥ä¾¿æ¸…æ™°æ˜¾ç¤ºçŸ¢é‡
    skip = 4
    ax2.imshow(T, cmap='RdBu_r', aspect='equal', extent=[0, 3, 0, 1], alpha=0.7)
    ax2.quiver(X[::skip, ::skip], Y[::skip, ::skip],
               U[::skip, ::skip], W[::skip, ::skip],
               scale=3, width=0.003, alpha=0.8)
    ax2.set_title('Flow Field Vectors')
    ax2.set_xlabel('x')
    ax2.set_ylabel('y')

    plt.tight_layout()

    # ä¿å­˜æµåœºå›¾
    flow_file = f"{save_path}/rb_flow_field.png"
    plt.savefig(flow_file, dpi=150, bbox_inches='tight')
    print(f"âœ… æµåœºå›¾ä¿å­˜: {flow_file}")

    plt.close('all')


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='åŸºäºåŸæœ‰ä»£ç çš„æ”¹è¿›RBæ•°æ®ç”Ÿæˆå™¨')
    parser.add_argument('--Ra', type=float, default=1e5, help='ç‘åˆ©æ•°')
    parser.add_argument('--n_runs', type=int, default=5, help='è¿è¡Œæ¬¡æ•°')
    parser.add_argument('--n_samples', type=int, default=50, help='æ¯æ¬¡è¿è¡Œçš„æ ·æœ¬æ•°')
    parser.add_argument('--nx', type=int, default=128, help='Xæ–¹å‘ç½‘æ ¼ç‚¹')
    parser.add_argument('--ny', type=int, default=64, help='Yæ–¹å‘ç½‘æ ¼ç‚¹')
    parser.add_argument('--save_path', type=str, default='rb_data_improved', help='ä¿å­˜è·¯å¾„')
    parser.add_argument('--visualize', action='store_true', help='åˆ›å»ºå¯è§†åŒ–')

    args = parser.parse_args()

    print("ğŸ”§ åŸºäºåŸæœ‰ä»£ç çš„æ”¹è¿›RBæ•°æ®ç”Ÿæˆå™¨")
    print("=" * 50)
    print("ä¿æŒåŸæœ‰ä»£ç ç»“æ„ï¼Œä¿®å¤æ•°å€¼ç¨³å®šæ€§")
    print()

    # ç”Ÿæˆæ•°æ®
    generate_training_dataset_improved(
        Ra=args.Ra,
        n_runs=args.n_runs,
        n_samples=args.n_samples,
        nx=args.nx,
        ny=args.ny,
        save_path=args.save_path
    )

    # å¯è§†åŒ–
    if args.visualize:
        data_file = f"{args.save_path}/rb2d_ra{args.Ra:.0e}_consolidated.h5"
        if os.path.exists(data_file):
            create_visualization(data_file, args.save_path)

    print("\nâœ… æ”¹è¿›æ•°æ®ç”Ÿæˆå®Œæˆï¼")
    print(f"ğŸ“ æ•°æ®ä¿å­˜åœ¨: {args.save_path}/")
    print("ğŸš€ ç°åœ¨å¯ä»¥ç”¨äºCDAnetè®­ç»ƒï¼")