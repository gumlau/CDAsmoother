#!/usr/bin/env python3
"""
Working training example with correct dimensions and checkpointing
"""

import torch
import torch.nn as nn
import os
from cdanet.models import CDAnet
from cdanet.data import RBDataModule

def main():
    print("üöÄ CDAsmoother Working Training Example")
    print("="*60)
    
    # Setup data with the real dimensions from verification
    print("Setting up data module...")
    data_module = RBDataModule(
        data_dir='./rb_data_numerical',
        spatial_downsample=4,
        temporal_downsample=4,
        clip_length=8,
        batch_size=1,  # Small batch for CPU
        num_workers=0,
        pde_points=100,  # Small for speed
        normalize=True
    )
    
    data_module.setup([1e5])
    train_loader = data_module.get_dataloader(1e5, 'train')
    
    print(f"‚úÖ Data loaded: {len(train_loader)} batches available")
    
    # Get one real batch to see dimensions
    print("Loading a real batch...")
    batch = next(iter(train_loader))
    
    low_res_shape = batch['low_res'].shape
    targets_shape = batch['targets'].shape
    coords_shape = batch['coords'].shape
    
    print(f"Real data shapes:")
    print(f"  Low-res: {low_res_shape}")
    print(f"  Targets: {targets_shape}")  
    print(f"  Coords: {coords_shape}")
    
    # Create model with smaller parameters for CPU training
    print("\nCreating CDAnet model...")
    model = CDAnet(
        in_channels=4,
        feature_channels=128,  # Reduced for CPU
        mlp_hidden_dims=[256, 256],  # Smaller MLP
        activation='softplus',
        coord_dim=3,
        output_dim=4
    )
    
    total_params = sum(p.numel() for p in model.parameters())
    print(f"‚úÖ Model created: {total_params:,} parameters")
    
    # Setup training
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.MSELoss()
    
    # Training loop for 1 batch
    print("\nRunning training on 1 batch...")
    model.train()
    
    low_res = batch['low_res']
    targets = batch['targets'] 
    coords = batch['coords']
    
    print(f"Processing batch with {coords.shape[1]} coordinate points...")
    
    # Forward pass
    optimizer.zero_grad()
    predictions = model(low_res, coords)
    loss = criterion(predictions, targets)
    
    print(f"‚úÖ Forward pass successful!")
    print(f"  Predictions shape: {predictions.shape}")
    print(f"  Loss: {loss.item():.6f}")
    
    # Backward pass
    loss.backward()
    optimizer.step()
    
    print(f"‚úÖ Backward pass successful!")
    
    # Save checkpoint
    print("\nSaving checkpoint...")
    os.makedirs("./checkpoints", exist_ok=True)
    checkpoint_path = "./checkpoints/working_example_checkpoint.pth"
    
    torch.save({
        'epoch': 1,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'loss': loss.item(),
        'batch_shapes': {
            'low_res': low_res_shape,
            'targets': targets_shape,
            'coords': coords_shape
        }
    }, checkpoint_path)
    
    checkpoint_size = os.path.getsize(checkpoint_path) / (1024*1024)
    print(f"‚úÖ Checkpoint saved: {checkpoint_path}")
    print(f"  Size: {checkpoint_size:.1f} MB")
    
    # Save training results
    print("\nSaving training results...")
    os.makedirs("./outputs", exist_ok=True)
    results_path = "./outputs/working_training_results.txt"
    
    with open(results_path, 'w') as f:
        f.write("CDAsmoother Working Training Results\n")
        f.write("="*50 + "\n\n")
        f.write("‚úÖ TRAINING PIPELINE VERIFICATION SUCCESSFUL!\n\n")
        f.write("Components Verified:\n")
        f.write("- ‚úÖ Data loading with real RB simulation data\n")
        f.write("- ‚úÖ CDAnet model creation and initialization\n")
        f.write("- ‚úÖ Forward pass through 3D U-Net + Physics MLP\n")
        f.write("- ‚úÖ Loss computation and backward pass\n")
        f.write("- ‚úÖ Optimizer step and parameter updates\n")
        f.write("- ‚úÖ Checkpoint saving and model persistence\n\n")
        f.write(f"Model Details:\n")
        f.write(f"- Parameters: {total_params:,}\n")
        f.write(f"- Input shape: {low_res_shape}\n")
        f.write(f"- Output shape: {predictions.shape}\n")
        f.write(f"- Training loss: {loss.item():.6f}\n\n")
        f.write("Data Details:\n")
        f.write(f"- Ra number: 1e5\n")
        f.write(f"- Training batches: {len(train_loader)}\n")
        f.write(f"- Spatial downsampling: 4x\n")
        f.write(f"- Temporal downsampling: 4x\n\n")
        f.write("The complete CDAsmoother pipeline is working correctly!\n")
        f.write("You can now run full training with:\n")
        f.write("python3 train_cdanet.py --Ra 1e5 --spatial_downsample 4 --temporal_downsample 4 --num_epochs 10\n")
    
    print(f"‚úÖ Results saved: {results_path}")
    
    print(f"\n{'='*60}")
    print("üéâ SUCCESS! CDAsmoother Pipeline is Working!")
    print("="*60)
    print("‚úÖ All components verified and working correctly")
    print("‚úÖ Model trains successfully on real RB data")
    print("‚úÖ Checkpoints save properly")
    print("‚úÖ Ready for full training!")
    print("="*60)
    
    return True

if __name__ == "__main__":
    try:
        success = main()
        if success:
            print("\nüöÄ You can now run full training!")
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()